@article{aickinAdjustingMultipleTesting1996,
  title = {Adjusting for Multiple Testing When Reporting Research Results: The {{Bonferroni}} vs {{Holm}} Methods.},
  shorttitle = {Adjusting for Multiple Testing When Reporting Research Results},
  author = {Aickin, M and Gensler, H},
  year = {1996},
  month = may,
  journal = {American Journal of Public Health},
  volume = {86},
  number = {5},
  pages = {726--728},
  publisher = {American Public Health Association},
  issn = {0090-0036},
  doi = {10.2105/AJPH.86.5.726},
  urldate = {2024-03-12},
  abstract = {Public health researchers are sometimes required to make adjustments for multiple testing in reporting their results, which reduces the apparent significance of effects and thus reduces statistical power. The Bonferroni procedure is the most widely recommended way of doing this, but another procedure, that of Holm, is uniformly better. Researchers may have neglected Holm's procedure because it has been framed in terms of hypothesis test rejection rather than in terms of P values. An adjustment to P values based on Holm's method is presented in order to promote the method's use in public health research.},
  file = {/Users/zenn/Zotero/storage/3IGA3KSI/Aickin and Gensler - 1996 - Adjusting for multiple testing when reporting rese.pdf}
}

@article{benderAdjustingMultipleTesting2001a,
  title = {Adjusting for Multiple Testing---When and How?},
  author = {Bender, Ralf and Lange, Stefan},
  year = {2001},
  month = apr,
  journal = {Journal of Clinical Epidemiology},
  volume = {54},
  number = {4},
  pages = {343--349},
  issn = {08954356},
  doi = {10.1016/S0895-4356(00)00314-0},
  urldate = {2024-03-12},
  abstract = {Multiplicity of data, hypotheses, and analyses is a common problem in biomedical and epidemiological research. Multiple testing theory provides a framework for defining and controlling appropriate error rates in order to protect against wrong conclusions. However, the corresponding multiple test procedures are underutilized in biomedical and epidemiological research. In this article, the existing multiple test procedures are summarized for the most important multiplicity situations. It is emphasized that adjustments for multiple testing are required in confirmatory studies whenever results from multiple tests have to be combined in one final conclusion and decision. In case of multiple significance tests a note on the error rate that will be controlled for is desirable. {\copyright} 2001 Elsevier Science Inc. All rights reserved.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/JBIWLDZF/Bender and Lange - 2001 - Adjusting for multiple testingâ€”when and how.pdf}
}

@article{benjaminiControllingFalseDiscovery1995,
  title = {Controlling the {{False Discovery Rate}}: {{A Practical}} and {{Powerful Approach}} to {{Multiple Testing}}},
  shorttitle = {Controlling the {{False Discovery Rate}}},
  author = {Benjamini, Yoav and Hochberg, Yosef},
  year = {1995},
  month = jan,
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {57},
  number = {1},
  pages = {289--300},
  issn = {0035-9246, 2517-6161},
  doi = {10.1111/j.2517-6161.1995.tb02031.x},
  urldate = {2024-03-12},
  abstract = {SUMMARY             The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses --- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/6A2875BR/Benjamini and Hochberg - 1995 - Controlling the False Discovery Rate A Practical .pdf}
}

@article{benjaminiMultipleHypothesesTesting1997a,
  title = {Multiple {{Hypotheses Testing}} with {{Weights}}},
  author = {Benjamini, Yoav and Hochberg, Yosef},
  year = {1997},
  journal = {Scandinavian Journal of Statistics},
  volume = {24},
  number = {3},
  pages = {407--418},
  issn = {1467-9469},
  doi = {10.1111/1467-9469.00072},
  urldate = {2024-03-12},
  abstract = {In this paper we offer a multiplicity of approaches and procedures for multiple testing problems with weights. Some rationale for incorporating weights in multiple hypotheses testing are discussed. Various type-I error-rates and different possible formulations are considered, for both the intersection hypothesis testing and the multiple hypotheses testing problems. An optimal per family weighted error-rate controlling procedure a la Spjotvoll (1972) is obtained. This model serves as a vehicle for demonstrating the different implications of the approaches to weighting. Alternative approach es to that of Holm (1979) for family-wise error-rate control with weights are discussed, one involving an alternative procedure for family-wise error-rate control, and the other involving the control of a weighted family-wise error-rate. Extensions and modifications of the procedures based on Simes (1986) are given. These include a test of the overall intersec tion hypothesis with general weights, and weighted sequentially rejective procedures for testing the individual hypotheses. The false discovery rate controlling approach and procedure of Benjamini \& Hochberg (1995) are extended to allow for different weights.},
  copyright = {Board of the Foundation  of the Scandinavian Journal of Statistics 1997},
  langid = {english},
  keywords = {control weights,false discovery rate,family-wise error-rate,p-values,per-family error-rate,procedural weights},
  file = {/Users/zenn/Zotero/storage/ZY6KQYMT/Benjamini and Hochberg - 1997 - Multiple Hypotheses Testing with Weights.pdf;/Users/zenn/Zotero/storage/IAKSGWDA/1467-9469.html}
}

@article{blakesleyComparisonsMethodsMultiple2009,
  title = {Comparisons of Methods for Multiple Hypothesis Testing in Neuropsychological Research},
  author = {Blakesley, Richard E. and Mazumdar, Sati and Dew, Mary Amanda and Houck, Patricia R. and Tang, Gong and Reynolds III, Charles F. and Butters, Meryl A.},
  year = {2009},
  journal = {Neuropsychology},
  volume = {23},
  number = {2},
  pages = {255--264},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1931-1559},
  doi = {10.1037/a0012850},
  abstract = {Hypothesis testing with multiple outcomes requires adjustments to control Type I error inflation, which reduces power to detect significant differences. Maintaining the prechosen Type I error level is challenging when outcomes are correlated. This problem concerns many research areas, including neuropsychological research in which multiple, interrelated assessment measures are common. Standard p value adjustment methods include Bonferroni-, Sidak-, and resampling-class methods. In this report, the authors aimed to develop a multiple hypothesis testing strategy to maximize power while controlling Type I error. The authors conducted a sensitivity analysis, using a neuropsychological dataset, to offer a relative comparison of the methods and a simulation study to compare the robustness of the methods with respect to varying patterns and magnitudes of correlation between outcomes. The results lead them to recommend the Hochberg and Hommel methods (step-up modifications of the Bonferroni method) for mildly correlated outcomes and the step-down minP method (a resampling-based method) for highly correlated outcomes. The authors note caveats regarding the implementation of these methods using available software. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Error Analysis,Hypothesis Testing,Test Performance,Testing,Type I Errors},
  file = {/Users/zenn/Zotero/storage/5EYWYFN7/Blakesley et al. - 2009 - Comparisons of methods for multiple hypothesis tes.pdf;/Users/zenn/Zotero/storage/YIZM9BCY/2009-02621-013.html}
}

@article{hochbergSharperBonferroniProcedure1988a,
  title = {A Sharper {{Bonferroni}} Procedure for Multiple Tests of Significance},
  author = {HOCHBERG, {\relax YOSEF}},
  year = {1988},
  month = dec,
  journal = {Biometrika},
  volume = {75},
  number = {4},
  pages = {800--802},
  issn = {0006-3444},
  doi = {10.1093/biomet/75.4.800},
  urldate = {2024-03-12},
  abstract = {A simple procedure for multiple tests of significance based on individual p-values is derived. This simple procedure is sharper than Holm's (1979) sequentially rejective procedure. Both procedures contrast the ordered p- values with the same set of critical values. Holm's procedure rejects an hypothesis only if its p-value and each of the smaller p-values are less than their corresponding critical-values. The new procedure rejects all hypotheses with smaller or equal p-values to that of any one found less than its critical value.},
  file = {/Users/zenn/Zotero/storage/ZRVNAJ8W/HOCHBERG - 1988 - A sharper Bonferroni procedure for multiple tests .pdf;/Users/zenn/Zotero/storage/G2K5NBNB/423177.html}
}

@article{kochStatisticalConsiderationsMultiplicity1996,
  title = {Statistical {{Considerations}} for {{Multiplicity}} in {{Confirmatory Protocols}}},
  author = {Koch, Gary G. and Gansky, Stuart A.},
  year = {1996},
  month = apr,
  journal = {Drug Information Journal},
  volume = {30},
  number = {2},
  pages = {523--534},
  publisher = {SAGE Publications},
  issn = {0092-8615},
  doi = {10.1177/009286159603000228},
  urldate = {2024-03-12},
  abstract = {Statistical issues concerning multiple response criteria, multiple treatment groups, and multiple subgroups in clinical trials require careful attention in order to avoid an inappropriately high prevalence of chance findings, as well as to avoid unsatisfactorily low power to detect real treatment differences. An underlying goal is using a 0.050 significance level as often as possible for separate assessments while maintaining a 0.050 level for all assessments taken together, so statistical power is not compromised. For multiple response criteria, a useful assessment strategy is composite ranking as a single criterion first and then its individual components. Multiple treatment comparisons can often be effectively addressed with closed testing procedures with hierarchical evaluation. This hierarchy must be well specified since significance at its first stage is required before testing is allowed at the next stage. In most clinical trials, subgroups are of supportive interest after statistical significance for all patients is shown. A subgroup hierarchy, however, permits primary evaluation in conjunction with all patients through significance level spending function methods as in interim analyses, for example, the O'Brien-Fleming method. The rationale is the analogy between a subgroup hierarchy and the patient hierarchy at successive interim analyses. With this method, the significance level for all patients' evaluation typically ranges between 0.040 and 0.045 and that for subgroups ranges from 0.005-0.020. The methods outlined here for multiple response criteria, multiple treatment groups, and subgroups, or related counterparts, should be prespecified in the protocol for a clinical trial. If not in the protocol, they should be incorporated in the analysis plan prior to study unmasking.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/J5NXZE96/Koch and Gansky - 1996 - Statistical Considerations for Multiplicity in Con.pdf}
}

@article{levinHolmSimesHochberg1996,
  title = {On the {{Holm}}, {{Simes}}, and {{Hochberg}} Multiple Test Procedures.},
  author = {Levin, B},
  year = {1996},
  month = may,
  journal = {American Journal of Public Health},
  volume = {86},
  number = {5},
  pages = {628--629},
  issn = {0090-0036, 1541-0048},
  doi = {10.2105/AJPH.86.5.628},
  urldate = {2024-03-12},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SQGVVTLZ/Levin - 1996 - On the Holm, Simes, and Hochberg multiple test pro.pdf}
}
